{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df870754-c9b3-400f-b2ad-6520d4cf0dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNaive Bayes multi-class classifier inplemented from scratch.\\nHandles zero frequency corrections/smoothing.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Naive Bayes multi-class classifier inplemented from scratch.\n",
    "Handles zero frequency corrections/smoothing.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3fa0e3-bdd8-4d9c-aa38-bf5c8b6fc80e",
   "metadata": {},
   "source": [
    "### 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35404177-1909-4745-8d83-c74c15eebb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy\n",
    "import pandas\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f23b06-f383-4470-bec3-37e779b4ab62",
   "metadata": {},
   "source": [
    "### 1. Imports and pre-processing data\n",
    "\n",
    "We load the data into a Pandas DataFrame, then we preprocess it by adding a column with the (non-repeated) lowercase words in the email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1a956f9-d8bb-4b64-a101-454205f52b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Subject: great nnews  hello , welcome to medzo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Subject: here ' s a hot play in motion  homela...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Subject: save your money buy getting this thin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Subject: undeliverable : home based business f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Subject: save your money buy getting this thin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam\n",
       "0  Subject: naturally irresistible your corporate...     1\n",
       "1  Subject: the stock trading gunslinger  fanny i...     1\n",
       "2  Subject: unbelievable new homes made easy  im ...     1\n",
       "3  Subject: 4 color printing special  request add...     1\n",
       "4  Subject: do not have money , get software cds ...     1\n",
       "5  Subject: great nnews  hello , welcome to medzo...     1\n",
       "6  Subject: here ' s a hot play in motion  homela...     1\n",
       "7  Subject: save your money buy getting this thin...     1\n",
       "8  Subject: undeliverable : home based business f...     1\n",
       "9  Subject: save your money buy getting this thin...     1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Environment variables\n",
    "dir_path = pathlib.Path.cwd()\n",
    "name_dataset = \"emails.csv\"\n",
    "\n",
    "column_emails = \"text\"\n",
    "column_words = \"words\"\n",
    "column_label = \"spam\"\n",
    "label_spam = 1\n",
    "label_ham = 0\n",
    "\n",
    "# Read dataset\n",
    "emails = pandas.read_csv(dir_path / name_dataset)\n",
    "emails[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2f7d230-0d96-48c4-8189-3096a7d6171f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers (Preprocess) =========================================\n",
    "\n",
    "def split_string_into_unique_words(string):\n",
    "    return list(set(string.split()))\n",
    "\n",
    "def process_series_email(series_text):\n",
    "    \"\"\" Converts text to lower-case then returns list of unique words \"\"\"\n",
    "    series_words = series_text.copy() # copies original series\n",
    "    series_words = series_words.str.lower()\n",
    "    series_words = series_words.apply(split_string_into_unique_words)\n",
    "\n",
    "    return series_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7eb615e-e8fd-40b3-9461-3a4d2e4ce88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "      <td>[information, content, market, marketing, brea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "      <td>[attainder, yes, palfrey, no, is, segovia, pep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[at, way, all, complete, 3, 72, no, dorcas, is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "      <td>[information, &amp;, pdf, rd, is, format, printabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[get, cds, all, be, grow, it, old, is, marriag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Subject: great nnews  hello , welcome to medzo...</td>\n",
       "      <td>1</td>\n",
       "      <td>[shakedown, miilion, countries, op, is, andman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Subject: here ' s a hot play in motion  homela...</td>\n",
       "      <td>1</td>\n",
       "      <td>[\", aiways, sec, into, applications, rf, risk,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Subject: save your money buy getting this thin...</td>\n",
       "      <td>1</td>\n",
       "      <td>[any, get, bed, country, can, be, start, it, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Subject: undeliverable : home based business f...</td>\n",
       "      <td>1</td>\n",
       "      <td>[l, recognized, for, -, 21, q, ;, ims, based, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Subject: save your money buy getting this thin...</td>\n",
       "      <td>1</td>\n",
       "      <td>[any, get, bed, country, can, be, start, it, i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam  \\\n",
       "0  Subject: naturally irresistible your corporate...     1   \n",
       "1  Subject: the stock trading gunslinger  fanny i...     1   \n",
       "2  Subject: unbelievable new homes made easy  im ...     1   \n",
       "3  Subject: 4 color printing special  request add...     1   \n",
       "4  Subject: do not have money , get software cds ...     1   \n",
       "5  Subject: great nnews  hello , welcome to medzo...     1   \n",
       "6  Subject: here ' s a hot play in motion  homela...     1   \n",
       "7  Subject: save your money buy getting this thin...     1   \n",
       "8  Subject: undeliverable : home based business f...     1   \n",
       "9  Subject: save your money buy getting this thin...     1   \n",
       "\n",
       "                                               words  \n",
       "0  [information, content, market, marketing, brea...  \n",
       "1  [attainder, yes, palfrey, no, is, segovia, pep...  \n",
       "2  [at, way, all, complete, 3, 72, no, dorcas, is...  \n",
       "3  [information, &, pdf, rd, is, format, printabl...  \n",
       "4  [get, cds, all, be, grow, it, old, is, marriag...  \n",
       "5  [shakedown, miilion, countries, op, is, andman...  \n",
       "6  [\", aiways, sec, into, applications, rf, risk,...  \n",
       "7  [any, get, bed, country, can, be, start, it, i...  \n",
       "8  [l, recognized, for, -, 21, q, ;, ims, based, ...  \n",
       "9  [any, get, bed, country, can, be, start, it, i...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails[column_words] = process_series_email(emails[column_emails])\n",
    "emails[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2105c758-c370-4352-9633-bafbe0057730",
   "metadata": {},
   "source": [
    "### 2. Calculating prior probabilities\n",
    "Let's calculate the probabilities of seeing a ham or spam email from just the labeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cd21916-7022-43c9-8418-ef69b068869c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers (Priors) ========================================\n",
    "\n",
    "def calculate_frequency_average(series):\n",
    "    \"\"\" Calculates probabilites of occurences of each label out of the entire set \"\"\"\n",
    "    try:\n",
    "        series_averages = series.value_counts() / len(series)\n",
    "        return series_averages.to_dict()\n",
    "    except ZeroDivisionError as exception:\n",
    "        raise exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fff48fc-012f-4e2b-8ce4-3697613583ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4360\n",
      "1    1368\n",
      "Name: spam, dtype: int64\n",
      "Number of emails: 5728\n",
      "Number of spam emails: 1368\n",
      "Probability of spam: 0.2388268156424581\n"
     ]
    }
   ],
   "source": [
    "# Our label column is boolean, with spam being 1 and ham being 0.\n",
    "num_emails = len(emails)\n",
    "counts_label = emails[column_label].value_counts()\n",
    "num_spam = counts_label[label_spam]\n",
    "print(counts_label)\n",
    "\n",
    "print(\"Number of emails:\", num_emails)\n",
    "print(\"Number of spam emails:\", num_spam)\n",
    "\n",
    "# Calculating the prior probability an email is spam.\n",
    "dict_priors = calculate_frequency_average(emails[column_label])\n",
    "print(\"Probability of spam:\", dict_priors[label_spam])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a23754d-630e-4181-9586-7d99be584646",
   "metadata": {},
   "source": [
    "### 3. Training a Naive Bayes model\n",
    "We need to calculate the text's word frequencies in order to train the model. Our plan is to write a dictionary that records every word, and calculate its pair of occurrences in spam and ham. Sometimes, if we train on new text, we may see a word that we haven't seen before. In order for the math to check out (avoid dividing by zero), we may have to add a tiny number, and we'll use the whole text to cook up this number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3161f72-140e-407e-8cf7-8fc45b460de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers (Dictionaries) =========================================\n",
    "\n",
    "def merge_dicts(dict1, dict2):\n",
    "    dictionary = dict1.copy()\n",
    "    dictionary.update(dict2)\n",
    "    return dictionary\n",
    "\n",
    "def construct_frequency_dict_from_series(series_text):\n",
    "    \"\"\" Converts text to lower-case then returns list of unique words \"\"\"\n",
    "    series_list_words = series_text.str.lower()\n",
    "    series_list_words = series_list_words.str.split()\n",
    "    series_list_words = series_list_words.explode()\n",
    "    series_counts = series_list_words.value_counts()\n",
    "    \n",
    "    return series_counts.to_dict()\n",
    "\n",
    "def construct_frequency_dict_from_strings(list_strings):\n",
    "    \"\"\" Converts text to lower-case then returns list of unique words \"\"\"\n",
    "    string = \" \".join(list_strings)\n",
    "    string = string.lower()\n",
    "    list_words = string.split()\n",
    "\n",
    "    return dict(collections.Counter(list_words))\n",
    "\n",
    "# Model =========================================\n",
    "def calculate_labeled_frequencies(dict_frequencies_text, dataframe_emails, column_label, column_words):\n",
    "    \"\"\" \n",
    "    Constructs a frequency dictionary for list of words \n",
    "    Uses a processed dataframe with list words column\n",
    "    \n",
    "    Handles zero frequency occurences by adding n(w) / total,\n",
    "    in which n(w) is the number of occurences of the word\n",
    "    across all text, and total is the total number of words\n",
    "    in the text.\n",
    "    \n",
    "    Parameter\n",
    "    ----------\n",
    "    dict_frequencies_text = { word : n(word) }\n",
    "    \n",
    "    \"\"\"\n",
    "    list_labels = dataframe_emails[column_label].unique()\n",
    "    total = sum(dict_frequencies_text.values())\n",
    "    \n",
    "    # Doing it this way avoids copy errors with nested dictionaries\n",
    "    model = {}\n",
    "    for word in dict_frequencies_text.keys():\n",
    "        model.setdefault(word, {label : 0 for label in list_labels })\n",
    "\n",
    "    # Split label column into groups so we can count them directly\n",
    "    group_labels = dataframe_emails.groupby(column_label)\n",
    "    for label, label_df in group_labels:\n",
    "        for list_words in label_df[column_words]:\n",
    "            for word in list_words:\n",
    "\n",
    "                model[word][label] += 1\n",
    "                \n",
    "    # Handles the zero frequency offset\n",
    "    for word, dict_frequency in model.items():\n",
    "        offset = max(dict_frequencies_text[word] / total, 1E-8)\n",
    "        for key in dict_frequency.keys():\n",
    "            dict_frequency[key] += offset\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c61565ec-ff0f-417a-b141-7f8fe4f7f15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate text word frequencies and train the model\n",
    "dict_frequencies_whole_text = construct_frequency_dict_from_series(emails[column_emails])\n",
    "dict_model = calculate_labeled_frequencies(dict_frequencies_whole_text, emails, column_label, column_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b35488a-39ef-4b11-bab8-b4dbc8c3ed0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 8.000010682682143, 0: 1.0682682143736557e-05}\n",
      "{1: 38.00005661821536, 0: 41.00005661821536}\n",
      "{1: 64.0002382238118, 0: 317.0002382238118}\n"
     ]
    }
   ],
   "source": [
    "# Some examples (1 is spam, and 0 is ham)\n",
    "print(dict_model['lottery'])\n",
    "print(dict_model['sale'])\n",
    "print(dict_model['already'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297942c9-8ea9-4a40-9b8d-588235cadf3f",
   "metadata": {},
   "source": [
    "### 3. Using the model to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d87eff2b-fc17-4758-9a5b-640b0ae69a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_bayes(word, label, dict_frequencies):\n",
    "    \"\"\" \n",
    "    Doesn't use the naive assumption.\n",
    "    likelihood = (num labeled emails with word) / sum(num labeled emails with word for all labels)\n",
    "               = P(A | Event_j) / sum ( P (A | Event_i) )\n",
    "    \"\"\"\n",
    "    label_count = dict_frequencies[word][label]\n",
    "    all_label_counts = sum(dict_frequencies[word].values())\n",
    "\n",
    "    try:\n",
    "        return label_count / all_label_counts\n",
    "    except ZeroDivisionError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ca260ab-71f2-4267-9a36-9e6fcd491c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999986646682983\n",
      "0.4810126854437434\n",
      "0.1679794178226178\n"
     ]
    }
   ],
   "source": [
    "print(predict_bayes('lottery', label_spam, dict_model))\n",
    "print(predict_bayes('sale', label_spam, dict_model))\n",
    "print(predict_bayes('already', label_spam, dict_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f63d73f-3cc5-4866-904f-de6aac50578b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers (Probabilities)\n",
    "\n",
    "def calculate_list_product(list_):\n",
    "    \"\"\" Slightly faster to work on arrays than directly with list \"\"\"\n",
    "    return numpy.array(list_).prod()\n",
    "\n",
    "# Naive Bayes Classifier\n",
    "\n",
    "def setup_naive_bayes(dict_frequencies_new_text, dataframe_emails, column_label, column_words):\n",
    "    \"\"\" \n",
    "    Adds new text to the model, so it can be used to make new predictions \n",
    "    This is mostly just an accumulation of the previous cells.\n",
    "    \"\"\"\n",
    "    \n",
    "    dict_frequencies_whole_text = construct_frequency_dict_from_series(dataframe_emails[column_emails])\n",
    "\n",
    "    dict_model = calculate_labeled_frequencies(\n",
    "        merge_dicts(dict_frequencies_whole_text, dict_frequencies_new_text), \n",
    "        dataframe_emails, \n",
    "        column_label, \n",
    "        column_words)\n",
    "\n",
    "    return dict_model\n",
    "\n",
    "def calculate_naive_bayes(list_words, dict_frequencies, series_labels):\n",
    "    list_labels = series_labels.unique()\n",
    "    counts_label = series_labels.value_counts()\n",
    "    total = len(series_labels)\n",
    "    \n",
    "    # Cook up the total number of emails in each label\n",
    "    dict_naive_bayes = { label : 1 for label in list_labels }\n",
    "    for word in list_words:\n",
    "        for label in list_labels:\n",
    "            probability = dict_frequencies[word][label] / counts_label[label]            \n",
    "            if probability == 0:\n",
    "                print(word)\n",
    "            dict_naive_bayes[label] *= (probability * total)\n",
    "\n",
    "    # Multiply by the total number of elements for each label \n",
    "    for label in list_labels:\n",
    "        dict_naive_bayes[label] *= counts_label[label]\n",
    "    \n",
    "    return dict_naive_bayes\n",
    "\n",
    "def predict_naive_bayes(email, label_to_predict, dict_frequencies, series_labels):\n",
    "    \"\"\" Uses the naive assumption to predict on a given email \"\"\"\n",
    "\n",
    "    # words\n",
    "    email = email.lower()\n",
    "    words = set(email.split())\n",
    "\n",
    "    dict_naive_bayes = calculate_naive_bayes(words, dict_frequencies, series_labels)\n",
    "    \n",
    "    numerator = dict_naive_bayes[label_to_predict]\n",
    "    denominator = sum(dict_naive_bayes.values())\n",
    "\n",
    "    return numerator/denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "108b4571-ab34-478c-82ad-d2c1d05827bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability email is spam:  0.9999999005387217\n",
      "Probability email is spam:  0.09520065375112553\n",
      "Probability email is spam:  0.25112821625045023\n",
      "Probability email is spam:  3.410728699614587e-11\n",
      "Probability email is spam:  0.9999999987178892\n",
      "Probability email is spam:  0.9999999999343989\n",
      "Probability email is spam:  0.9999999996071451\n",
      "Probability email is spam:  0.5000000000000001\n"
     ]
    }
   ],
   "source": [
    "list_emails = [\n",
    "    \"lottery sale\",\n",
    "    \"Hi mom how are you\",\n",
    "    \"Hi MOM how aRe yoU afdjsaklfsdhgjasdhfjklsd\",\n",
    "    \"meet me at the lobby of the hotel at nine am\",\n",
    "    \"enter the lottery to win three million dollars\",\n",
    "    \"buy cheap lottery easy money now\",\n",
    "    \"buy cheap lottery easy money\"\n",
    "    \"Grokking Machine Learning by Luis Serrano\",\n",
    "    \"asdfgh\"]\n",
    "\n",
    "dict_frequencies_new_words = construct_frequency_dict_from_strings(list_emails)\n",
    "dict_model = setup_naive_bayes(dict_frequencies_new_words, emails, column_label, column_words)\n",
    "cout = \"Probability email is spam: \"\n",
    "for email in list_emails:\n",
    "    print(cout, predict_naive_bayes(email, label_spam, dict_model, emails[column_label]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0f4a84-63ff-41b6-b27e-c31161a15a2f",
   "metadata": {},
   "source": [
    "### 4. Do our results make sense?\n",
    "The \"Grokking Machine Learning by Luis Serrano\" classification was surprising. Or was it? Let's check how often a word like \"serrano\" appears in spam emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da96cb2d-9ff2-4d22-aaf3-20204bd154c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 1.0000005876034477, 0: 5.876034475869477e-07}\n",
      "0.9999994123972429\n"
     ]
    }
   ],
   "source": [
    "print(dict_model['serrano'])\n",
    "print(predict_bayes('serrano', label_spam, dict_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdb2eea-64c2-4061-bfa4-843452e9337f",
   "metadata": {},
   "source": [
    "Hmm, that seeems pretty high. But, if we look closer at the training data, the following email was labaled spam and has \"serrano\"!\n",
    "\n",
    "> Subject: important announcement : your application was approved  we tried to contact you last week about refinancing your home at a lower rate .  i would like to inform you know that you have been pre - approved .  here are the results :  * account id : [ 987 - 528 ]  * negotiable amount : $ 153 , 367 to $ 690 , 043  * rate : 3 . 70 % - 5 . 68 %  please fill out this quick form and we will have a broker contact you as soon as possible .  regards ,  shannon **serrano** senior account manager  lyell national lenders , llc .  database deletion :  www . lend - bloxz . com / r . php\n",
    "\n",
    "Talk about bad luck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a333eb42-e9b7-4972-a640-fa8e509f87cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
